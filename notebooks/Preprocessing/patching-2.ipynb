{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelnour/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/abdelnour/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZNK3c107SymBool10guard_boolEPKcl'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import sys\n",
    "import dotenv\n",
    "sys.path.append(\"../..\")\n",
    "from src.transforms import ImageResizer,make_patches\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdelnour/Documents/4eme_anne/S2/projet/data/roi-dataset/BRACS_RoI/latest_version\n",
      "/home/abdelnour/Documents/4eme_anne/S2/projet/data/patched\n"
     ]
    }
   ],
   "source": [
    "ROI_DIR = dotenv.get_key(dotenv.find_dotenv(), \"DATA_DIR\")\n",
    "PATCHED_ROI_DIR = '/home/abdelnour/Documents/4eme_anne/S2/projet/data/patched'\n",
    "\n",
    "print(ROI_DIR)\n",
    "print(PATCHED_ROI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizer = ImageResizer()\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoiIDataset(torchvision.datasets.ImageFolder):\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img, label = super().__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        return path, img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558bf88cb3a3415d91fdf7d3cfe1c390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e94050c7b4183ae5a7794e24a0d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_ \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mclasses:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     os\u001b[39m.\u001b[39mmkdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PATCHED_ROI_DIR, split, class_))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m path,img,label \u001b[39min\u001b[39;49;00m tqdm(dataset): \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     class_ \u001b[39m=\u001b[39;49m dataset\u001b[39m.\u001b[39;49mclasses[label]       \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# resize the image\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[1;32m/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     img, label \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(index)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs[index][\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelnour/Documents/4eme_anne/S2/projet/notebooks/Preprocessing/patching-2.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m path, img, label\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/datasets/folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(f)\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/PIL/Image.py:933\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    886\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m    887\u001b[0m ):\n\u001b[1;32m    888\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    935\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    937\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.11/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = os.listdir(ROI_DIR)\n",
    "\n",
    "for split in splits:\n",
    "\n",
    "    print(f\"split = {split}\")\n",
    "\n",
    "    # create a new dataset\n",
    "    dataset = RoiIDataset(root=os.path.join(ROI_DIR, split))\n",
    "\n",
    "    # create a folder for this particular split\n",
    "    os.mkdir(os.path.join(PATCHED_ROI_DIR, split))\n",
    "\n",
    "    for class_ in dataset.classes:\n",
    "        os.mkdir(os.path.join(PATCHED_ROI_DIR, split, class_))\n",
    "        \n",
    "    for path,img,label in tqdm(dataset): \n",
    "\n",
    "        class_ = dataset.classes[label]       \n",
    "        \n",
    "        # resize the image\n",
    "        resized_img = resizer(img)\n",
    "\n",
    "        # convert the PIL image to tensor\n",
    "        tensor_img = to_tensor(resized_img)\n",
    "\n",
    "        # get a list of patches\n",
    "        patches = make_patches(tensor_img, 224, 224)\n",
    "\n",
    "        basename = os.path.basename(path)\n",
    "        name,extention = os.path.splitext(basename)\n",
    "\n",
    "        # save the patches to the disk\n",
    "        for i,patch in enumerate(patches):\n",
    "            pil_patch = to_pil(patch)\n",
    "            patch_path = os.path.join(PATCHED_ROI_DIR, split, class_, f'{name}_{i}.{extention}')\n",
    "            pil_patch.save(patch_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $PATCHED_ROI_DIR/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
